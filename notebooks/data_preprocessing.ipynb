{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = []\n",
    "sub_dirs_1 = [\"00\", \"01\", \"02\", \"03\", \"04\", ]\n",
    "sub_dirs_2 = [\"05\", \"06\", \"07\", \"08\", \"09\", ]\n",
    "\n",
    "# manually change the working sub_dirs (sub_dirs_1, sub_dirs_2)\n",
    "wd = sub_dirs_1\n",
    "assert wd in [sub_dirs_1, sub_dirs_2], \"working sub_dirs must be sub_dirs_1 or sub_dirs_2\"\n",
    "\n",
    "for sub_dir in sub_dirs_1:\n",
    "    wd = os.path.join('/', 'D:', 'imdb_0', 'imdb', sub_dir)\n",
    "\n",
    "    img_names += [\n",
    "        os.path.join(wd, img_name) \n",
    "        for img_name in os.listdir(wd) \n",
    "        if os.path.isfile(os.path.join(wd, img_name))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23484\n"
     ]
    }
   ],
   "source": [
    "print(len(img_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_dirs_1 has 23484 images\n",
    "offset = 0 if wd is sub_dirs_1 else 25000\n",
    "\n",
    "for st in range(0, len(img_names), 5000):\n",
    "    dataset_5000 = []\n",
    "    \n",
    "    for img_name in img_names[st : st+5000]:\n",
    "        img = cv2.imread(img_name)\n",
    "        dataset_5000.append(cv2.resize(img, (224, 224)))\n",
    "\n",
    "    dataset_5000 = np.array(dataset_5000, dtype=np.float32)\n",
    "    np.save(os.path.join('/', 'D:', 'Dataset', 'imdb', \"numpy_array\", f\"imdb_1_{(st+offset)//5000}\"), dataset_5000)\n",
    "    del dataset_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_cat = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70+']\n",
    "\n",
    "df = pd.read_csv('C:/cv_projects/imdb_metadata.csv', index_col=[0])\n",
    "df[oh_cat] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.age // 10 >= 7, '70+'] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cat'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'cat'] = df.age // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.cat>7, 'cat'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['age', 'gender', 'cat', 'min_x', 'max_x', 'min_y', 'max_y'] + oh_cat].to_csv('C:/cv_projects/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/cv_projects/labels.csv', index_col=[0])\n",
    "\n",
    "df['cat'] = df['age'] // 10\n",
    "df.loc[df.cat > 7, 'cat'] = 7\n",
    "\n",
    "df.to_csv('C:/cv_projects/labels.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
